{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "314896cf-7b4b-4adc-8e32-5d4347b8e31a",
   "metadata": {
    "id": "314896cf-7b4b-4adc-8e32-5d4347b8e31a"
   },
   "outputs": [],
   "source": [
    "import sys, os\n",
    "import requests\n",
    "import selenium\n",
    "from selenium import webdriver\n",
    "import requests\n",
    "from pandas import DataFrame\n",
    "from urllib.request import urlopen\n",
    "from bs4 import BeautifulSoup\n",
    "from datetime import datetime, timedelta\n",
    "import re\n",
    "from datetime import datetime\n",
    "import pickle, progressbar, json, glob, time\n",
    "from tqdm import tqdm\n",
    "\n",
    "###### 날짜 저장 ##########\n",
    "date = str(datetime.now())\n",
    "date = date[:date.rfind(':')].replace(' ', '_')\n",
    "date = date.replace(':','시') + '분'\n",
    "## 현재 시간\n",
    "a=str(datetime.now()-timedelta(days=1))\n",
    "a = a[:a.rfind(':')].replace('-', '.')\n",
    "a=a[:a.find(' ')]\n",
    "a\n",
    "sleep_sec = 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "144e0dbe-3285-46f8-b6c2-0fa0b2e512e9",
   "metadata": {
    "id": "144e0dbe-3285-46f8-b6c2-0fa0b2e512e9"
   },
   "outputs": [],
   "source": [
    "def cleanhtml(raw_html):\n",
    "  cleanr = re.compile('<.*?>|&([a-z0-9]+|#[0-9]{1,6}|#x[0-9a-f]{1,6});')\n",
    "  cleantext = re.sub(cleanr, '', raw_html)\n",
    "  return cleantext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "557223d8-e16f-4a2b-ac0b-328df6cd5ebc",
   "metadata": {
    "id": "557223d8-e16f-4a2b-ac0b-328df6cd5ebc",
    "outputId": "4b83be99-44ef-48df-9833-75f5d64c946c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "본문 크롤링에 필요한 함수를 로딩하고 있습니다...\n",
      "----------------------------------------------------------------------------------------------------\n",
      "검색할 언론사 : 머니투데이\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "검색할 키워드  :  카카오\n",
      "수집 뉴스의 수(숫자만 입력) :  1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "====================================================================================================\n",
      "\n",
      "브라우저를 실행시킵니다(자동 제어)\n",
      "\n",
      "설정한 언론사를 선택합니다.\n",
      "\n"
     ]
    },
    {
     "ename": "ElementNotInteractableException",
     "evalue": "Message: element not interactable\n  (Session info: headless chrome=92.0.4515.159)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mElementNotInteractableException\u001b[0m           Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-0b3cf6480418>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[0msearch_opn_btn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbrowser\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfind_element_by_xpath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'//a[@class=\"btn_option _search_option_open_btn\"]'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 114\u001b[0;31m \u001b[0msearch_opn_btn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclick\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    115\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msleep_sec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/multi/lib/python3.7/site-packages/selenium/webdriver/remote/webelement.py\u001b[0m in \u001b[0;36mclick\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     78\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclick\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m         \u001b[0;34m\"\"\"Clicks the element.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 80\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_execute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mCommand\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCLICK_ELEMENT\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     81\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0msubmit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/multi/lib/python3.7/site-packages/selenium/webdriver/remote/webelement.py\u001b[0m in \u001b[0;36m_execute\u001b[0;34m(self, command, params)\u001b[0m\n\u001b[1;32m    631\u001b[0m             \u001b[0mparams\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    632\u001b[0m         \u001b[0mparams\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'id'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_id\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 633\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    634\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    635\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfind_element\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mby\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mBy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mID\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/multi/lib/python3.7/site-packages/selenium/webdriver/remote/webdriver.py\u001b[0m in \u001b[0;36mexecute\u001b[0;34m(self, driver_command, params)\u001b[0m\n\u001b[1;32m    319\u001b[0m         \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcommand_executor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdriver_command\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    320\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 321\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merror_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcheck_response\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    322\u001b[0m             response['value'] = self._unwrap_value(\n\u001b[1;32m    323\u001b[0m                 response.get('value', None))\n",
      "\u001b[0;32m/opt/anaconda3/envs/multi/lib/python3.7/site-packages/selenium/webdriver/remote/errorhandler.py\u001b[0m in \u001b[0;36mcheck_response\u001b[0;34m(self, response)\u001b[0m\n\u001b[1;32m    240\u001b[0m                 \u001b[0malert_text\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'alert'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'text'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    241\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mexception_class\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscreen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstacktrace\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malert_text\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 242\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mexception_class\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscreen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstacktrace\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    243\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    244\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_value_or_default\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdefault\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mElementNotInteractableException\u001b[0m: Message: element not interactable\n  (Session info: headless chrome=92.0.4515.159)\n"
     ]
    }
   ],
   "source": [
    "####### 언론사별 본문 위치 태그 파싱 함수 ###########\n",
    "print('본문 크롤링에 필요한 함수를 로딩하고 있습니다...\\n' + '-' * 100)\n",
    "\n",
    "\n",
    "def crawling_main_text(url):\n",
    "\n",
    "    req = requests.get(url)\n",
    "    req.encoding = None\n",
    "    soup = BeautifulSoup(req.text, 'html.parser')\n",
    "    dates = ''\n",
    "    res = [0 for i in range(2)]\n",
    "    \n",
    "    # 연합뉴스\n",
    "    if ('://yna' in url) | ('app.yonhapnews' in url): \n",
    "        main_article = soup.find('div', {'class':'story-news article'})\n",
    "        if main_article == None:\n",
    "            main_article = soup.find('div', {'class' : 'article-txt'})\n",
    "            \n",
    "        text = main_article.text\n",
    "        \n",
    "    # MBC \n",
    "    elif '//imnews.imbc' in url: \n",
    "        text = soup.find('div', {'itemprop' : 'articleBody'}).text\n",
    "        \n",
    "    # 매일경제(미라클), req.encoding = None 설정 필요\n",
    "    elif 'mirakle.mk' in url:\n",
    "        text = soup.find('div', {'class' : 'view_txt'}).text\n",
    "        \n",
    "    # 매일경제, req.encoding = None 설정 필요\n",
    "    elif 'mk.co' in url:\n",
    "        text = soup.find('div', {'class' : 'art_txt'}).text\n",
    "#         text2 = soup.find('li', {'class' : 'date'}).text\n",
    "#         dates = re.sub(r'[^0-9]', '', text2)\n",
    "\n",
    "\n",
    "#         text = cleanhtml(str(soup))\n",
    "#         text2 = soup.find('li', {'class' : 'lasttime'}).text\n",
    "#         dates = re.sub(r'[^0-9]', '', text2)\n",
    "\n",
    "#         try:\n",
    "#             text = soup.find('div', {'class' : 'art_txt'}).text\n",
    "#             text2 = soup.find('li', {'class' : 'lasttime'}).text\n",
    "#             dates = re.sub(r'[^0-9]', '', text2)\n",
    "#         except:\n",
    "#             try:\n",
    "#                 text = soup.find('div', {'class' : 'view_txt'}).text\n",
    "#             except:\n",
    "#                 text = 'None'\n",
    "#             text2 = soup.find('li', {'class' : 'lasttime'}).text\n",
    "#             dates = re.sub(r'[^0-9]', '', text2)\n",
    "\n",
    "#             html = urlopen(url)\n",
    "#             bsob = BeautifulSoup(html, 'html.parser')\n",
    "#             text = cleanhtml(str(bsob)).replace('\\n','')\n",
    "#             text2 = soup.find('li', {'class' : 'lasttime'}).text\n",
    "#             dates = re.sub(r'[^0-9]', '', text2)\n",
    "        \n",
    "    # SBS\n",
    "    elif 'news.sbs' in url:\n",
    "        text = soup.find('div', {'itemprop' : 'articleBody'}).text\n",
    "    \n",
    "    # KBS\n",
    "    elif 'news.kbs' in url:\n",
    "        text = soup.find('div', {'id' : 'cont_newstext'}).text\n",
    "        \n",
    "    # JTBC\n",
    "    elif 'news.jtbc' in url:\n",
    "        text = soup.find('div', {'class' : 'article_content'}).text\n",
    "        \n",
    "    # 머니투데이\n",
    "    elif 'news.mt' in url:\n",
    "        text = soup.find('div', {'class' : 'view_text'}).text\n",
    "        \n",
    "    # 그 외\n",
    "    else:\n",
    "        text == None\n",
    "        \n",
    "#     res[0] = text.replace('\\n','').replace('\\r','').replace('<br>','').replace('\\t','')\n",
    "#     res[1] = date[:10]\n",
    "    \n",
    "    return text\n",
    "\n",
    "\n",
    "press_nm = '머니투데이'\n",
    "\n",
    "print('검색할 언론사 : {}'.format(press_nm))\n",
    "\n",
    "\n",
    "############### 브라우저를 켜고 검색 키워드 입력 ####################\n",
    "query = input('검색할 키워드  : ')\n",
    "news_num = int(input('수집 뉴스의 수(숫자만 입력) : '))\n",
    "\n",
    "print('\\n' + '=' * 100 + '\\n')\n",
    "\n",
    "print('브라우저를 실행시킵니다(자동 제어)\\n')\n",
    "chrome_path = './chromedriver/chromedriver'\n",
    "options = webdriver.ChromeOptions()\n",
    "options.add_argument('headless')\n",
    "options.add_argument('window-size=1920x1080')\n",
    "options.add_argument(\"disable-gpu\")\n",
    "browser = webdriver.Chrome(chrome_path, options=options)\n",
    "\n",
    "news_url = 'https://search.naver.com/search.naver?where=news&query={}&sm=tab_opt&sort=0&photo=0& \\\n",
    "        field=0&pd=3&ds={}&de={}&start=1'.format(query,20200101,a)\n",
    "browser.get(news_url)\n",
    "time.sleep(sleep_sec)\n",
    "\n",
    "\n",
    "\n",
    "######### 언론사 선택 및 confirm #####################\n",
    "print('설정한 언론사를 선택합니다.\\n')\n",
    "\n",
    "search_opn_btn = browser.find_element_by_xpath('//a[@class=\"btn_option _search_option_open_btn\"]')\n",
    "search_opn_btn.click()\n",
    "time.sleep(sleep_sec)\n",
    "\n",
    "bx_press = browser.find_element_by_xpath('//div[@role=\"listbox\" and @class=\"api_group_option_sort _search_option_detail_wrap\"]//li[@class=\"bx press\"]')\n",
    "\n",
    "# 기준 두번 째(언론사 분류순) 클릭하고 오픈하기\n",
    "press_tablist = bx_press.find_elements_by_xpath('.//div[@role=\"tablist\" and @class=\"option\"]/a')\n",
    "press_tablist[1].click()\n",
    "time.sleep(sleep_sec)\n",
    "\n",
    "# 첫 번째 것(언론사 분류선택)\n",
    "bx_group = bx_press.find_elements_by_xpath('.//div[@class=\"api_select_option type_group _category_select_layer\"]/div[@class=\"select_wrap _root\"]')[0]\n",
    "\n",
    "press_kind_bx = bx_group.find_elements_by_xpath('.//div[@class=\"group_select _list_root\"]')[0]\n",
    "press_kind_btn_list = press_kind_bx.find_elements_by_xpath('.//ul[@role=\"tablist\" and @class=\"lst_item _ul\"]/li/a')\n",
    "\n",
    "\n",
    "for press_kind_btn in press_kind_btn_list:\n",
    "    \n",
    "    # 언론사 종류를 순차적으로 클릭(좌측)\n",
    "    press_kind_btn.click()\n",
    "    time.sleep(sleep_sec)\n",
    "    \n",
    "    # 언론사선택(우측)\n",
    "    press_slct_bx = bx_group.find_elements_by_xpath('.//div[@class=\"group_select _list_root\"]')[1]\n",
    "    # 언론사 선택할 수 있는 클릭 버튼\n",
    "    press_slct_btn_list = press_slct_bx.find_elements_by_xpath('.//ul[@role=\"tablist\" and @class=\"lst_item _ul\"]/li/a')\n",
    "    # 언론사 이름들 추출\n",
    "    press_slct_btn_list_nm = [psl.text for psl in press_slct_btn_list]\n",
    "    \n",
    "    # 언론사 이름 : 언론사 클릭 버튼 인 딕셔너리 생성\n",
    "    press_slct_btn_dict = dict(zip(press_slct_btn_list_nm, press_slct_btn_list))\n",
    "    \n",
    "    # 원하는 언론사가 해당 이름 안에 있는 경우\n",
    "    # 1) 클릭하고\n",
    "    # 2) 더이상 언론사분류선택 탐색 중지\n",
    "    if press_nm in press_slct_btn_dict.keys():\n",
    "        print('<{}> 카테고리에서 <{}>를 찾았으므로 탐색을 종료합니다'.format(press_kind_btn.text, press_nm))\n",
    "        \n",
    "        press_slct_btn_dict[press_nm].click()\n",
    "        time.sleep(sleep_sec)\n",
    "        \n",
    "        break\n",
    "          \n",
    "################ 뉴스 크롤링 ########################\n",
    "\n",
    "print('\\n크롤링을 시작합니다.')\n",
    "# ####동적 제어로 페이지 넘어가며 크롤링\n",
    "news_dict = {}\n",
    "idx = 1\n",
    "cur_page = 1\n",
    "\n",
    "pbar = tqdm(total=news_num ,leave = True)\n",
    "    \n",
    "while idx < news_num:\n",
    "\n",
    "    table = browser.find_element_by_xpath('//ul[@class=\"list_news\"]')\n",
    "    li_list = table.find_elements_by_xpath('./li[contains(@id, \"sp_nws\")]')\n",
    "    area_list = [li.find_element_by_xpath('.//div[@class=\"news_area\"]') for li in li_list]\n",
    "    a_list = [area.find_element_by_xpath('.//a[@class=\"news_tit\"]') for area in area_list]\n",
    " \n",
    "    for n in a_list[:min(len(a_list), news_num-idx+1)]:\n",
    "        n_url = n.get_attribute('href')\n",
    "        news_dict[idx] = {'title' : n.get_attribute('title'), \n",
    "                          'url' : n_url,\n",
    "                          'text' : crawling_main_text(n_url),\n",
    "                          'date' : str(n_url)[n_url.find('no=')+3:n_url.find('no=')+13]}\n",
    "        \n",
    "        idx += 1\n",
    "        pbar.update(1)\n",
    "        \n",
    "    if idx < news_num:\n",
    "        cur_page +=1\n",
    "\n",
    "        pages = browser.find_element_by_xpath('//div[@class=\"sc_page_inner\"]')\n",
    "        next_page_url = [p for p in pages.find_elements_by_xpath('.//a') if p.text == str(cur_page)][0].get_attribute('href')\n",
    "\n",
    "        browser.get(next_page_url)\n",
    "        time.sleep(sleep_sec)\n",
    "    else:\n",
    "        pbar.close()\n",
    "        \n",
    "        print('\\n브라우저를 종료합니다.\\n' + '=' * 100)\n",
    "        time.sleep(0.7)\n",
    "        browser.close()\n",
    "        break\n",
    "        \n",
    "#### 데이터 전처리하기 ###################################################### \n",
    "\n",
    "print('데이터프레임 변환\\n')\n",
    "news_df = DataFrame(news_dict).T\n",
    "\n",
    "folder_path = os.getcwd()\n",
    "xlsx_file_name = '네이버뉴스_본문_{}개_{}_{}.xlsx'.format(news_num, query, date)\n",
    "\n",
    "news_df.to_excel(xlsx_file_name)\n",
    "\n",
    "print('엑셀 저장 완료 | 경로 : {}\\\\{}\\n'.format(folder_path, xlsx_file_name))\n",
    "\n",
    "os.startfile(folder_path)\n",
    "\n",
    "print('=' * 100 + '\\n결과물의 일부')\n",
    "news_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25597a74-0a79-4803-ba46-4219286a9499",
   "metadata": {
    "id": "25597a74-0a79-4803-ba46-4219286a9499"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72a06b4c-cfda-4b3f-ba4e-7ea8ccabe0a8",
   "metadata": {
    "id": "72a06b4c-cfda-4b3f-ba4e-7ea8ccabe0a8"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "background_crwaling.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python Multi",
   "language": "python",
   "name": "multi"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
